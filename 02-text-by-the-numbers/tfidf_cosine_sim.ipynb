{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the Similarity of Texts using TF-IDF\n",
    "\n",
    "This notebook is modeled on the *Programming Historian* lesson [Understanding and Using Common Similarity Measures for Text Analysis](https://programminghistorian.org/en/lessons/common-similarity-measures) by John Ladd. Please visit this webpage for more explanation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Setup\n",
    "\n",
    "### Ia. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "import glob \n",
    "import pandas as pd, numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer  \n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "from nltk.corpus import stopwords\n",
    "stop = sorted(stopwords.words('english'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ib. Read in text files and create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdir = Path(\"~/shared/RR-workshop-data/state-of-the-union-dataset/txt\").expanduser() \n",
    "pathlist = sorted(textdir.glob('*.txt')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#n=50\n",
    "\n",
    "txtList=[]\n",
    "pathlist = sorted(textdir.glob('*.txt'))      # .glob only stores the pathlist temporarily (for some reason), so you need to call it again!2\n",
    "for path in pathlist:\n",
    "    fn=path.stem                       #stem returns the filename minus the \".txt\" (file extension). \n",
    "    pres,year=fn.split(\"_\")            # fn = \"1794_Washington\" becomes year = \"1794\" and pres = \"Washington\"\n",
    "    with open(path,'r') as f:  \n",
    "        text1 = f.read()                #opens each file and reads it in as \"sotu\"\n",
    "    tokens=tokenizer.tokenize(text1)    # tokenizes \"sotu\"\n",
    "    numtoks = len(tokens)             # counts the number of tokens in \"sotu\"\n",
    "    ltokens_ns = [tok.lower() for tok in tokens if tok not in stop]\n",
    "    txtList.append([pres, year, numtoks, tokens, ltokens_ns, text1])   #add this info for \"sotu\" to a running list for all sotu addresses\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pres</th>\n",
       "      <th>year</th>\n",
       "      <th>numtoks</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ltoks_ns</th>\n",
       "      <th>fulltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams</td>\n",
       "      <td>1797</td>\n",
       "      <td>2060</td>\n",
       "      <td>[Gentlemen, of, the, Senate, and, Gentlemen, o...</td>\n",
       "      <td>[gentlemen, senate, gentlemen, house, represen...</td>\n",
       "      <td>Gentlemen of the Senate and Gentlemen of the H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adams</td>\n",
       "      <td>1798</td>\n",
       "      <td>2218</td>\n",
       "      <td>[Gentlemen, of, the, Senate, and, Gentlemen, o...</td>\n",
       "      <td>[gentlemen, senate, gentlemen, house, represen...</td>\n",
       "      <td>Gentlemen of the Senate and Gentlemen of the H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adams</td>\n",
       "      <td>1799</td>\n",
       "      <td>1505</td>\n",
       "      <td>[Gentlemen, of, the, Senate, and, Gentlemen, o...</td>\n",
       "      <td>[gentlemen, senate, gentlemen, house, represen...</td>\n",
       "      <td>Gentlemen of the Senate and Gentlemen of the H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adams</td>\n",
       "      <td>1800</td>\n",
       "      <td>1374</td>\n",
       "      <td>[Gentlemen, of, the, Senate, and, Gentlemen, o...</td>\n",
       "      <td>[gentlemen, senate, gentlemen, house, represen...</td>\n",
       "      <td>Gentlemen of the Senate and Gentlemen of the H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adams</td>\n",
       "      <td>1825</td>\n",
       "      <td>9091</td>\n",
       "      <td>[Fellow, Citizens, of, the, Senate, and, of, t...</td>\n",
       "      <td>[fellow, citizens, senate, house, representati...</td>\n",
       "      <td>Fellow Citizens of the Senate and of the House...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adams</td>\n",
       "      <td>1826</td>\n",
       "      <td>7852</td>\n",
       "      <td>[Fellow, Citizens, of, the, Senate, and, of, t...</td>\n",
       "      <td>[fellow, citizens, senate, house, representati...</td>\n",
       "      <td>Fellow Citizens of the Senate and of the House...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adams</td>\n",
       "      <td>1827</td>\n",
       "      <td>7064</td>\n",
       "      <td>[Fellow, Citizens, of, the, Senate, and, of, t...</td>\n",
       "      <td>[fellow, citizens, senate, house, representati...</td>\n",
       "      <td>Fellow Citizens of the Senate and of the House...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adams</td>\n",
       "      <td>1828</td>\n",
       "      <td>7398</td>\n",
       "      <td>[Fellow, Citizens, of, the, Senate, and, of, t...</td>\n",
       "      <td>[fellow, citizens, senate, house, representati...</td>\n",
       "      <td>Fellow Citizens of the Senate and of the House...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arthur</td>\n",
       "      <td>1881</td>\n",
       "      <td>3903</td>\n",
       "      <td>[To, the, Senate, and, House, of, Representati...</td>\n",
       "      <td>[to, senate, house, representatives, united, s...</td>\n",
       "      <td>To the Senate and House of Representatives of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arthur</td>\n",
       "      <td>1882</td>\n",
       "      <td>3157</td>\n",
       "      <td>[To, the, Senate, and, House, of, Representati...</td>\n",
       "      <td>[to, senate, house, representatives, united, s...</td>\n",
       "      <td>To the Senate and House of Representatives of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pres  year  numtoks                                             tokens  \\\n",
       "0   Adams  1797     2060  [Gentlemen, of, the, Senate, and, Gentlemen, o...   \n",
       "1   Adams  1798     2218  [Gentlemen, of, the, Senate, and, Gentlemen, o...   \n",
       "2   Adams  1799     1505  [Gentlemen, of, the, Senate, and, Gentlemen, o...   \n",
       "3   Adams  1800     1374  [Gentlemen, of, the, Senate, and, Gentlemen, o...   \n",
       "4   Adams  1825     9091  [Fellow, Citizens, of, the, Senate, and, of, t...   \n",
       "5   Adams  1826     7852  [Fellow, Citizens, of, the, Senate, and, of, t...   \n",
       "6   Adams  1827     7064  [Fellow, Citizens, of, the, Senate, and, of, t...   \n",
       "7   Adams  1828     7398  [Fellow, Citizens, of, the, Senate, and, of, t...   \n",
       "8  Arthur  1881     3903  [To, the, Senate, and, House, of, Representati...   \n",
       "9  Arthur  1882     3157  [To, the, Senate, and, House, of, Representati...   \n",
       "\n",
       "                                            ltoks_ns  \\\n",
       "0  [gentlemen, senate, gentlemen, house, represen...   \n",
       "1  [gentlemen, senate, gentlemen, house, represen...   \n",
       "2  [gentlemen, senate, gentlemen, house, represen...   \n",
       "3  [gentlemen, senate, gentlemen, house, represen...   \n",
       "4  [fellow, citizens, senate, house, representati...   \n",
       "5  [fellow, citizens, senate, house, representati...   \n",
       "6  [fellow, citizens, senate, house, representati...   \n",
       "7  [fellow, citizens, senate, house, representati...   \n",
       "8  [to, senate, house, representatives, united, s...   \n",
       "9  [to, senate, house, representatives, united, s...   \n",
       "\n",
       "                                            fulltext  \n",
       "0  Gentlemen of the Senate and Gentlemen of the H...  \n",
       "1  Gentlemen of the Senate and Gentlemen of the H...  \n",
       "2  Gentlemen of the Senate and Gentlemen of the H...  \n",
       "3  Gentlemen of the Senate and Gentlemen of the H...  \n",
       "4  Fellow Citizens of the Senate and of the House...  \n",
       "5  Fellow Citizens of the Senate and of the House...  \n",
       "6  Fellow Citizens of the Senate and of the House...  \n",
       "7  Fellow Citizens of the Senate and of the House...  \n",
       "8  To the Senate and House of Representatives of ...  \n",
       "9  To the Senate and House of Representatives of ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames=['pres','year','numtoks','tokens', 'ltoks_ns', 'fulltext']\n",
    "textdf=pd.DataFrame(txtList, columns=colnames)  #places our completed list of SOTU info in a dataframe\n",
    "textdf.head(10)                                #prints out the first 10 rows of this dataframe (the default value for head() is 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pres</th>\n",
       "      <th>year</th>\n",
       "      <th>numtoks</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ltoks_ns</th>\n",
       "      <th>fulltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Biden</td>\n",
       "      <td>2023</td>\n",
       "      <td>9624</td>\n",
       "      <td>[Mr, Speaker, Thank, you, You, can, smile, it,...</td>\n",
       "      <td>[mr, speaker, thank, you, smile, ok, thank, th...</td>\n",
       "      <td>Mr. Speaker. Thank you. You can smile, it's OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Biden</td>\n",
       "      <td>2022</td>\n",
       "      <td>8137</td>\n",
       "      <td>[Thank, you, all, very, very, much, Thank, you...</td>\n",
       "      <td>[thank, much, thank, please, thank, much, mada...</td>\n",
       "      <td>Thank you all very, very much. Thank you, plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Biden</td>\n",
       "      <td>2021</td>\n",
       "      <td>8351</td>\n",
       "      <td>[Thank, you, Thank, you, Thank, you, Good, to,...</td>\n",
       "      <td>[thank, thank, thank, good, back, as, mitch, c...</td>\n",
       "      <td>Thank you. Thank you. Thank you. Good to be ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2020</td>\n",
       "      <td>6474</td>\n",
       "      <td>[Thank, you, very, much, Thank, you, Thank, yo...</td>\n",
       "      <td>[thank, much, thank, thank, much, madam, speak...</td>\n",
       "      <td>Thank you very much. Thank you. Thank you very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2019</td>\n",
       "      <td>5777</td>\n",
       "      <td>[Madam, Speaker, Mr, Vice, President, Members,...</td>\n",
       "      <td>[madam, speaker, mr, vice, president, members,...</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2018</td>\n",
       "      <td>5204</td>\n",
       "      <td>[Mr, Speaker, Mr, Vice, President, Members, of...</td>\n",
       "      <td>[mr, speaker, mr, vice, president, members, co...</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2017</td>\n",
       "      <td>5095</td>\n",
       "      <td>[Thank, you, very, much, Mr, Speaker, Mr, Vice...</td>\n",
       "      <td>[thank, much, mr, speaker, mr, vice, president...</td>\n",
       "      <td>Thank you very much. Mr. Speaker, Mr. Vice Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Obama</td>\n",
       "      <td>2016</td>\n",
       "      <td>5628</td>\n",
       "      <td>[Mr, Speaker, Mr, Vice, President, Members, of...</td>\n",
       "      <td>[mr, speaker, mr, vice, president, members, co...</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Obama</td>\n",
       "      <td>2015</td>\n",
       "      <td>6961</td>\n",
       "      <td>[Mr, Speaker, Mr, Vice, President, Members, of...</td>\n",
       "      <td>[mr, speaker, mr, vice, president, members, co...</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Obama</td>\n",
       "      <td>2014</td>\n",
       "      <td>7017</td>\n",
       "      <td>[Mr, Speaker, Mr, Vice, President, Members, of...</td>\n",
       "      <td>[mr, speaker, mr, vice, president, members, co...</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pres  year  numtoks                                             tokens  \\\n",
       "14   Biden  2023     9624  [Mr, Speaker, Thank, you, You, can, smile, it,...   \n",
       "13   Biden  2022     8137  [Thank, you, all, very, very, much, Thank, you...   \n",
       "12   Biden  2021     8351  [Thank, you, Thank, you, Thank, you, Good, to,...   \n",
       "213  Trump  2020     6474  [Thank, you, very, much, Thank, you, Thank, yo...   \n",
       "212  Trump  2019     5777  [Madam, Speaker, Mr, Vice, President, Members,...   \n",
       "211  Trump  2018     5204  [Mr, Speaker, Mr, Vice, President, Members, of...   \n",
       "210  Trump  2017     5095  [Thank, you, very, much, Mr, Speaker, Mr, Vice...   \n",
       "161  Obama  2016     5628  [Mr, Speaker, Mr, Vice, President, Members, of...   \n",
       "160  Obama  2015     6961  [Mr, Speaker, Mr, Vice, President, Members, of...   \n",
       "159  Obama  2014     7017  [Mr, Speaker, Mr, Vice, President, Members, of...   \n",
       "\n",
       "                                              ltoks_ns  \\\n",
       "14   [mr, speaker, thank, you, smile, ok, thank, th...   \n",
       "13   [thank, much, thank, please, thank, much, mada...   \n",
       "12   [thank, thank, thank, good, back, as, mitch, c...   \n",
       "213  [thank, much, thank, thank, much, madam, speak...   \n",
       "212  [madam, speaker, mr, vice, president, members,...   \n",
       "211  [mr, speaker, mr, vice, president, members, co...   \n",
       "210  [thank, much, mr, speaker, mr, vice, president...   \n",
       "161  [mr, speaker, mr, vice, president, members, co...   \n",
       "160  [mr, speaker, mr, vice, president, members, co...   \n",
       "159  [mr, speaker, mr, vice, president, members, co...   \n",
       "\n",
       "                                              fulltext  \n",
       "14   Mr. Speaker. Thank you. You can smile, it's OK...  \n",
       "13   Thank you all very, very much. Thank you, plea...  \n",
       "12   Thank you. Thank you. Thank you. Good to be ba...  \n",
       "213  Thank you very much. Thank you. Thank you very...  \n",
       "212  Madam Speaker, Mr. Vice President, Members of ...  \n",
       "211  Mr. Speaker, Mr. Vice President, Members of Co...  \n",
       "210  Thank you very much. Mr. Speaker, Mr. Vice Pre...  \n",
       "161  Mr. Speaker, Mr. Vice President, Members of Co...  \n",
       "160  Mr. Speaker, Mr. Vice President, Members of Co...  \n",
       "159  Mr. Speaker, Mr. Vice President, Members of Co...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf.sort_values(by = \"year\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Create a TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\F0040RP\\Documents\\DartLib_RDS\\intro-to-python\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.43991929 0.403336   ... 0.19580329 0.18803809 0.20870311]\n",
      " [0.43991929 1.         0.36556119 ... 0.18971342 0.18305033 0.18292755]\n",
      " [0.403336   0.36556119 1.         ... 0.20212655 0.19737592 0.20642286]\n",
      " ...\n",
      " [0.19580329 0.18971342 0.20212655 ... 1.         0.40592595 0.31038614]\n",
      " [0.18803809 0.18305033 0.19737592 ... 0.40592595 1.         0.38413319]\n",
      " [0.20870311 0.18292755 0.20642286 ... 0.31038614 0.38413319 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer   ###\n",
    "\n",
    "# Interface lemma tokenizer from nltk with sklearn\n",
    "class LemmaTokenizer:                                               ###\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']      ###\n",
    "    def __init__(self):                                             ###\n",
    "        self.wnl = WordNetLemmatizer()                              ###\n",
    "    def __call__(self, doc):                                        ###\n",
    "        #return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]\n",
    "        return [self.wnl.lemmatize(t) for t in tokenizer.tokenize(doc) if t not in self.ignore_tokens]    ###\n",
    "    \n",
    "lemma_tokenizer = LemmaTokenizer()                                 ###\n",
    "eng_stops = set(stopwords.words('english'))                        ###\n",
    "lemma_stop = lemma_tokenizer(' '.join(eng_stops))   \n",
    "tfidf_vectorizer3 = TfidfVectorizer(input = \"filename\", stop_words = lemma_stop, tokenizer = lemma_tokenizer)\n",
    "tfidf_matrix = tfidf_vectorizer3.fit_transform(pathlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "#print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Measuring similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Adams_1797  Adams_1798  Adams_1799  Adams_1800  Adams_1825  \\\n",
      "Adams_1797     0.000000    1.058377    1.092396    1.139157    1.140426   \n",
      "Adams_1798     1.058377    0.000000    1.126445    1.171412    1.168071   \n",
      "Adams_1799     1.092396    1.126445    0.000000    1.136175    1.197776   \n",
      "Adams_1800     1.139157    1.171412    1.136175    0.000000    1.175189   \n",
      "Adams_1825     1.140426    1.168071    1.197776    1.175189    0.000000   \n",
      "...                 ...         ...         ...         ...         ...   \n",
      "Wilson_1916    1.269018    1.277528    1.279998    1.255958    1.196267   \n",
      "Wilson_1917    1.299209    1.288659    1.280381    1.286824    1.228714   \n",
      "Wilson_1918    1.268225    1.273017    1.263229    1.265470    1.179491   \n",
      "Wilson_1919    1.274333    1.278241    1.266984    1.273079    1.173514   \n",
      "Wilson_1920    1.258012    1.278337    1.259823    1.260161    1.135219   \n",
      "\n",
      "             Adams_1826  Adams_1827  Adams_1828  Arthur_1881  Arthur_1882  \\\n",
      "Adams_1797     1.142499    1.132971    1.127780     1.206957     1.240203   \n",
      "Adams_1798     1.180275    1.163855    1.171404     1.233068     1.260325   \n",
      "Adams_1799     1.182290    1.179087    1.181514     1.220941     1.253516   \n",
      "Adams_1800     1.194705    1.199578    1.178595     1.251060     1.267880   \n",
      "Adams_1825     0.866532    0.877309    0.888573     1.163190     1.192404   \n",
      "...                 ...         ...         ...          ...          ...   \n",
      "Wilson_1916    1.219710    1.227031    1.211009     1.290234     1.277670   \n",
      "Wilson_1917    1.260735    1.264974    1.242290     1.298734     1.306169   \n",
      "Wilson_1918    1.211066    1.211301    1.191811     1.269272     1.277667   \n",
      "Wilson_1919    1.201459    1.207505    1.178577     1.250694     1.260272   \n",
      "Wilson_1920    1.117082    1.148100    1.146658     1.242701     1.262598   \n",
      "\n",
      "             ...  Washington_1795  Washington_1796  Wilson_1913  Wilson_1914  \\\n",
      "Adams_1797   ...         1.177604         1.067754     1.256424     1.228366   \n",
      "Adams_1798   ...         1.215970         1.087153     1.267428     1.233573   \n",
      "Adams_1799   ...         1.199888         1.146993     1.249342     1.260788   \n",
      "Adams_1800   ...         1.199902         1.158071     1.250670     1.239174   \n",
      "Adams_1825   ...         1.173536         1.088753     1.179896     1.172136   \n",
      "...          ...              ...              ...          ...          ...   \n",
      "Wilson_1916  ...         1.267625         1.252535     1.159415     1.155517   \n",
      "Wilson_1917  ...         1.301191         1.254689     1.182554     1.120826   \n",
      "Wilson_1918  ...         1.270902         1.227773     1.119396     1.082719   \n",
      "Wilson_1919  ...         1.260853         1.241848     1.143063     1.130594   \n",
      "Wilson_1920  ...         1.279997         1.247671     1.176669     1.176499   \n",
      "\n",
      "             Wilson_1915  Wilson_1916  Wilson_1917  Wilson_1918  Wilson_1919  \\\n",
      "Adams_1797      1.256362     1.269018     1.299209     1.268225     1.274333   \n",
      "Adams_1798      1.256094     1.277528     1.288659     1.273017     1.278241   \n",
      "Adams_1799      1.268110     1.279998     1.280381     1.263229     1.266984   \n",
      "Adams_1800      1.251596     1.255958     1.286824     1.265470     1.273079   \n",
      "Adams_1825      1.130020     1.196267     1.228714     1.179491     1.173514   \n",
      "...                  ...          ...          ...          ...          ...   \n",
      "Wilson_1916     1.178422     0.000000     1.229973     1.165305     1.143445   \n",
      "Wilson_1917     1.159120     1.229973     0.000000     1.135045     1.154530   \n",
      "Wilson_1918     1.075282     1.165305     1.135045     0.000000     1.090022   \n",
      "Wilson_1919     1.116877     1.143445     1.154530     1.090022     0.000000   \n",
      "Wilson_1920     1.144287     1.192969     1.207346     1.174405     1.109835   \n",
      "\n",
      "             Wilson_1920  \n",
      "Adams_1797      1.258012  \n",
      "Adams_1798      1.278337  \n",
      "Adams_1799      1.259823  \n",
      "Adams_1800      1.260161  \n",
      "Adams_1825      1.135219  \n",
      "...                  ...  \n",
      "Wilson_1916     1.192969  \n",
      "Wilson_1917     1.207346  \n",
      "Wilson_1918     1.174405  \n",
      "Wilson_1919     1.109835  \n",
      "Wilson_1920     0.000000  \n",
      "\n",
      "[233 rows x 233 columns]\n"
     ]
    }
   ],
   "source": [
    "textnamelist = [path.stem for path in pathlist]\n",
    "euclidean_distances = pd.DataFrame(squareform(pdist(tfidf_array)), index=textnamelist, columns=textnamelist)\n",
    "print(euclidean_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buchanan_1858    0.982063\n",
      "Polk_1848        0.992604\n",
      "Grant_1875       0.992755\n",
      "Grant_1873       0.995843\n",
      "Lincoln_1863     0.995844\n",
      "Johnson_1867     0.998771\n",
      "Buchanan_1860    0.999609\n",
      "Buchanan_1857    1.001766\n",
      "Johnson_1865     1.002945\n",
      "Name: Lincoln_1862, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tgt = \"Lincoln_1862\"      #try plugging in the names of different SOTU addresses, to view possible choices, enter the following in a new code cell: `textnamelist`\n",
    "top5_euclidean = euclidean_distances.nsmallest(10, tgt)[tgt][1:]\n",
    "print(top5_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reagan_1982     0.414717\n",
      "Clinton_1993    0.426629\n",
      "Carter_1978     0.426772\n",
      "Reagan_1984     0.433686\n",
      "Reagan_1985     0.447053\n",
      "Name: Reagan_1983, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cosine_distances = pd.DataFrame(squareform(pdist(tfidf_array, metric='cosine')), index=textnamelist, columns=textnamelist)\n",
    "\n",
    "top5_cosine = cosine_distances.nsmallest(6, tgt)[tgt][1:]\n",
    "print(top5_cosine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
