{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who wrote that?\n",
    "## Identifying Authorship and Studying Style with Stylometry\n",
    "\n",
    "This lesson is adapted from François Dominic Laramée's [\"Introduction to stylometry with Python\"](https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python) lesson published on the [*Programming Historian*](https://programminghistorian.org/) webpage (in 2018). It is also available in French and Portuguese. All sections labeled with the initial **[PH]** are copied directly from this lesson, while those labeled **[~PH~]** are modified versions of this lesson. If you benefit from this lesson, please consider supporting the *Programming Historian*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to stylometry\n",
    "\n",
    "Stylometry is the study of literary style using computational methods. Among other things, it provides a means for estimating identifying the most likely author of an unattributed text from a selection of attributed works by known authors. \n",
    "\n",
    "As Laramée explains [PH]:\n",
    "\n",
    "```\n",
    "[Stylometry] is based on the observation that authors tend to write in relatively consistent, recognizable and unique ways. For example:\n",
    "\n",
    "    * Each person has their own unique vocabulary, sometimes rich, sometimes limited. Although a larger vocabulary is usually associated with literary quality, this is not always the case. Ernest Hemingway is famous for using a surprisingly small number of different words in his writing, which did not prevent him from winning the Nobel Prize for Literature in 1954.\n",
    "    * Some people write in short sentences, while others prefer long blocks of text consisting of many clauses.\n",
    "    * No two people use semicolons, em-dashes, and other forms of punctuation in the exact same way.\n",
    "\n",
    "```\n",
    "\n",
    "As you may already observed, the study of an author's writing style requires an examination of text elements we normally ignore in computational text analysis. For example:\n",
    "+ **stopwords**: for most other forms of text analysis it helps to remove or ignore \"stopwords\" (words like \"and\", \"a\", \"the\", \"this\", and \"upon - conjunctions, prepositions, articles, etc.). These words reveal little about the context of a text. However, they are essential stylistic markers of authorship.\n",
    "+ **punctuation:** we often remove punctuation when tokenizing texts into individual words. However, the use of different types of punctuation often distinguishes one author from another. \n",
    "+ **sentence length** and **diversity of vocabulary**: (see above)\n",
    "\n",
    "***Note: Stylometry can predict the probability an anonymous text was written by a particular author from within a selection of authors for which we have sample documents. But, it can never say so for certain!***\n",
    "\n",
    "It is also comparative?? It can only identify a likely author if texts known to have been written by that author are available for comparison with the unattributed text(s).\n",
    "\n",
    "## Identification vs. Security and Anonymization\n",
    "\n",
    "Identifying the author of historical texts, such as the Federalist Papers, advances our understanding of the historical past.\n",
    "\n",
    "It can also help:\n",
    "+ educators to detect [plagiarism, cheating, and the use of ghost-writers](https://files.eric.ed.gov/fulltext/EJ1260339.pdf). \n",
    "+ law enforcement to: \n",
    "    + verify the author of a will or confession\n",
    "    + identify the criminal who wrote an anonymous letter or manifesto (like the \"Unabomber\")\n",
    "    + identify the origin of fake news and conspiracy theories (i.e. [QAnon](https://www.nytimes.com/2022/02/19/technology/qanon-messages-authors.html?searchResultPosition=1))\n",
    "+ Some scholars are currently experimenting with [the use of stylometric methods to identify the Large Language Model (LLM) used to create an AI-generated text](https://arxiv.org/pdf/2308.07305.pdf), while acknowledging [the limits of these methods to identify machine-generated texts](https://direct.mit.edu/coli/article/46/2/499/93369/The-Limitations-of-Stylometry-for-Detecting).    \n",
    "    \n",
    "\n",
    "However, in other cases, applying stylometry to identify living authors who have chosen to publish anonymously could cause harm to innocent people. Government security agencies have almost certainly used it to identify dissidents. Organizations could also use stylometry to identify and target anonymous critics or whistleblowers. \n",
    "\n",
    "Furthermore, since one could argue that the automated recognition of a person's writing style is a personal attribute like their fingerprints, DNA, or face (as used by facial reocgnition). If so, a person's writing style should perhaps be protected by the same regulations that protect biometric data processing. \n",
    "\n",
    "For this reason, the [legal and ethical implications of the uses of stylometry need to be explored further](https://www.law.kuleuven.be/citip/blog/show-me-how-you-write-and-ill-tell-you-who-you-are/).\n",
    "\n",
    "Some developers have developed software and programming packages (such as [Anonymouth](https://github.com/spencermwoo/anonymouth)) to conceal linguistic markers of a person's writing style and, thus, help them maintain their anonymity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, this lesson is adapted from François Dominic Laramée's [\"Introduction to stylometry with Python\"](https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python) lesson published on the [*Programming Historian*](https://programminghistorian.org/) webpage.\n",
    "\n",
    "A fuller version of my adapatation of the original PH lesson is available on our GitLab repository: https://git.dartmouth.edu/lib-digital-strategies/RDS/workshops/computational-tools/intro-to-python/-/blob/master/stylometry.ipynb. The original focused on identifying the author(s) of some unattributed letters found in the Federalist Paper.\n",
    "\n",
    "This version applies the 3rd of 3 stylometric methods introduced in that lesson to the State of the Union address corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd   #working with dataframes\n",
    "import nltk           # text analysis / NLP\n",
    "nltk.download('punkt')\n",
    "import collections    # for creating frequency lists\n",
    "\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedpapers_dir = Path(\"~/shared/RR-workshop-data/federalist-papers-dataset/split\").expanduser() \n",
    "pathlist = sorted(fedpapers_dir.glob('*.txt'))  \n",
    "print([file.name for file in pathlist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for Analysis [PH]\n",
    "\n",
    "Before we can proceed with stylometric analysis, we need to load the files containing all 85 papers into convenient data structures in computer memory.\n",
    "\n",
    "The first step in this process is to assign each of the 85 papers to the proper set. Since we have given each paper standardized names from federalist_1.txt to federalist_85.txt, it is possible to assign each paper to its author (or to its test set, if we want to learn its author’s identity) using a **Python dictionary**. The dictionary is a data type made up of an arbitrary number of key-value pairs; in this case, the names of authors will serve as keys, while the lists of paper numbers will be the values associated with these keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = {\n",
    "    'Madison': [10, 14, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
    "    'Hamilton': [1, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24,\n",
    "                 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 59, 60,\n",
    "                 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
    "                 78, 79, 80, 81, 82, 83, 84, 85],\n",
    "    'Jay': [2, 3, 4, 5],\n",
    "    'Shared': [18, 19, 20],\n",
    "    'Disputed': [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63],\n",
    "    'TestCase': [64]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python dictionaries are very flexible. For example, we can access a value by indexing the dictionary with one of its keys, we can scan the entire dictionary by looping over its list of keys, etc. We will make ample use of this functionality as we move along.\n",
    "\n",
    "Next, as we are interested in each author’s vocabulary, we will define a short Python function that creates a long listing of the words in each of the papers assigned to a single author. This will be stored as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that compiles all of the text files associated with a single author into a single string\n",
    "\"\"\"\n",
    "def read_files_into_string(filenames):\n",
    "    strings = []\n",
    "    for filename in filenames:\n",
    "        with open(f'data/federalist_{filename}.txt', 'r') as f:\n",
    "            strings.append(f.read())\n",
    "    return '\\n'.join(strings)\n",
    "\"\"\"\n",
    "\n",
    "def read_files_into_string(filenames):\n",
    "    strings = []\n",
    "    #for filename in filenames:\n",
    "    for filename in filenames:\n",
    "        #with open(path, 'r') as f:\n",
    "        #    strings.append(f.read())\n",
    "        with open(Path(fedpapers_dir, f'federalist_{filename}.txt'), 'r') as f:\n",
    "            strings.append(f.read())\n",
    "    return '\\n'.join(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we build a new data structure by repeatedly calling the ```read_files_into_string()``` function, passing it a different list of papers every time. We will store the results into another dictionary, this one with author/test case names as keys and all of the text of the relevant papers as values. For simplicity’s sake, we will refer to the string containing a list of papers as “the author’s corpus”, even when we are dealing with disputed or shared papers rather than with an individual’s known contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papers.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary out of the authors' corpora\n",
    "\n",
    "#pathlist = sorted(fedpapers_dir.glob('*.txt'))      # .glob only stores the pathlist temporarily (for some reason), so you need to call it again!2\n",
    "\n",
    "#for path in pathlist:\n",
    "#    print(path.name)\n",
    "\n",
    "federalist_by_author = {}\n",
    "for author, files in papers.items():\n",
    "    federalist_by_author[author] = read_files_into_string(files)\n",
    "    #federalist_by_author[author] = read_files_into_string(pathlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the files loaded properly, print the first hundred characters of each dictionary entry to screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in papers:\n",
    "    print(\"**\", author, \"**\")\n",
    "    print(federalist_by_author[author][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this printing operation yields anything at all, then the file input operation has worked as expected and you can move on to stylometric analysis.\n",
    "\n",
    "*If the files fail to load, the most likely reason is that your current working directory is not the `data` repository created by unzipping the archive from the Required Materials section above; changing your working directory should do the trick. How you do this depends on your Python development environment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Stylometric Test: John Burrows’ Delta Method (Advanced)\n",
    "\n",
    "The first two stylometric methods were easy to implement. This next one, based on John Burrows’ Delta statistic16, is considerably more involved, both conceptually (the mathematics are more complicated) and computationally (more code required). It is, however, one of the most prominent stylometric methods in use today.\n",
    "\n",
    "**Like Kilgariff’s chi-squared, Burrows’ Delta is a measure of the “distance” between a text whose authorship we want to ascertain and some other corpus. Unlike chi-squared, however, the Delta Method is designed to compare an anonymous text (or set of texts) to many different authors’ signatures at the same time.** More precisely, Delta measures how the anonymous text and sets of texts written by an arbitrary number of known authors all diverge from the average of all of them put together. Furthermore, the Delta Method gives equal weight to every feature that it measures, thus avoiding the problem of common words overwhelming the results, which was an issue with chi-squared tests. For all of these reasons, John Burrows’ Delta Method is usually a more effective solution to the problem of authorship.\n",
    "\n",
    "Burrows’ original algorithm can be summarized as follows:\n",
    "\n",
    "+ Assemble a large corpus made up of texts written by an arbitrary number of authors; let’s say that number of authors is x.\n",
    "+ Find the n most frequent words in the corpus to use as features.\n",
    "+ For each of these n features, calculate the share of each of the x authors’ subcorpora represented by this feature, as a percentage of the total number of words. As an example, the word “the” may represent 4.72% of the words in Author A’s subcorpus.\n",
    "+ Then, calculate the mean and the standard deviation of these x values and use them as the offical mean and standard deviation for this feature over the whole corpus. In other words, we will be using a mean of means instead of calculating a single value representing the share of the entire corpus represented by each word. \n",
    "    + This is because we want to avoid a larger subcorpus, like Hamilton’s in our case, over-influencing the results in its favor and defining the corpus norm in such a way that everything would be expected to look like it.\n",
    "\n",
    "+ For each of the n features and x subcorpora, calculate a z-score describing how far away from the corpus norm the usage of this particular feature in this particular subcorpus happens to be. To do this, subtract the “mean of means” for the feature from the feature’s frequency in the subcorpus and divide the result by the feature’s standard deviation. Figure 7 shows the z-score equation for feature ‘i’, where C(i) represents the observed frequency, the greek letter mu represents the mean of means, and the greek letter sigma, the standard deviation.\n",
    "    \n",
    "\n",
    "<img src = \"https://programminghistorian.org/images/introduction-to-stylometry-with-python/stylometry-python-7.jpg\">\n",
    "\n",
    "Figure 7: Equation for the z-score statistic.\n",
    "\n",
    "+ Then, calculate the same z-scores for each feature in the text for which we want to determine authorship.\n",
    "\n",
    "+ Finally, calculate a delta score comparing the anonymous paper with each candidate’s subcorpus. To do this, take the average of the absolute values of the differences between the z-scores for each feature between the anonymous paper and the candidate’s subcorpus. (Read that twice!) This gives equal weight to each feature, no matter how often the words occur in the texts; otherwise, the top 3 or 4 features would overwhelm everything else. Figure 8 shows the equation for Delta, where Z(c,i) is the z-score for feature ‘i’ in candidate ‘c’, and Z(t,i) is the z-score for feature ‘i’ in the test case.\n",
    "    \n",
    "<img src = \"https://programminghistorian.org/images/introduction-to-stylometry-with-python/stylometry-python-8.jpg\">\n",
    "\n",
    "Figure 8: Equation for John Burrows’ Delta statistic.\n",
    "\n",
    "The “winning” candidate is the author for whom the delta score between the author’s subcorpus and the test case is the lowest.\n",
    "\n",
    "Stefan Evert et al.17 provide an in-depth discussion of the method’s variants, refinements and intricacies, but we will stick to the essentials for the purposes of this lesson. A different explanation of Delta, written in Spanish, and an application to a corpus of Spanish novels can also be found in a recent paper by José Calvo Tello.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Test Case\n",
    "\n",
    "As our test case, we will use Federalist 64. Alexander Hamtilton claimed to be the author of this paper in his letter; however, a draft of Federalist 64 was later found in John Jay’s personal papers and everyone concluded that Jay was in fact the author. No foul play is suspected, by the way: in the same letter, Hamilton attributed to Jay the authorship of another paper with a similar number that Hamilton himself had clearly written. Perhaps Hamilton was distracted by his pending duel and simply misremembered.\n",
    "\n",
    "Since John Burrows’ Delta Method works with an arbitrary number of candidate authors (Burrows’ original paper uses about 25), we will compare Federalist 64’s stylistic signature with those of five corpora: Hamilton’s papers, Madison’s papers, Jay’s other papers, the papers co-written by Madison and Hamilton, and the papers disputed between Hamilton and Madison. **We expect the Delta Method to tell us that Jay is the most likely author; any other result would call into question either the method, or the historiography, or both.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Let’s combine all of the subcorpora into a single corpus for Delta to calculate a “standard” to work with. Then, let’s select a number of words to use as features. Remember that we used 500 words to calculate Kilgariff’s chi-squared; this time, we will use a smaller set of 30 words, most if not all of them function words and common verbs, as our features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[JM Note:]\n",
    "The code below iterates through the dictionary of text we created (which we called `federalist_by_author`). Calling, `federalist_by_author[\"Hamilton\"]` for example returns all 51 texts written by Hamilton, combined into one long text string. It then creates a second dictionary `federalist_by_author_tokens` with a list of tokens for each author's texts and a third dictionary, `federalist_by_author_length_distributions` containing a frequency distribution graph for each author's texts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the authors' corpora into lists of word tokens\n",
    "federalist_by_author_tokens = {}\n",
    "federalist_by_author_length_distributions = {}\n",
    "for author in authors:\n",
    "    tokens = nltk.word_tokenize(federalist_by_author[author])\n",
    "\n",
    "    # Filter out punctuation  #$$ but this also filters out numbers, should we use isalnum() instead?\n",
    "    federalist_by_author_tokens[author] = ([token for token in tokens\n",
    "                                            if any(c.isalpha() for c in token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who are we dealing with this time?\n",
    "authors = (\"Hamilton\", \"Madison\", \"Jay\", \"Disputed\", \"Shared\")\n",
    "\n",
    "# Convert papers to lowercase to count all tokens of the same word together\n",
    "# regardless of case\n",
    "\n",
    "\n",
    "for author in authors:\n",
    "    federalist_by_author_tokens[author] = (\n",
    "        [tok.lower() for tok in federalist_by_author_tokens[author]])\n",
    "\n",
    "# Combine every paper except our test case into a single corpus\n",
    "whole_corpus = []\n",
    "for author in authors:\n",
    "    whole_corpus += federalist_by_author_tokens[author]\n",
    "\n",
    "# Get a frequency distribution\n",
    "whole_corpus_freq_dist = list(nltk.FreqDist(whole_corpus).most_common(30))\n",
    "whole_corpus_freq_dist[ :10 ]  #outputs the ten most common words and their frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating features for each subcorpus\n",
    "\n",
    "Let’s look at the frequencies of each feature in each candidate’s subcorpus, as a proportion of the total number of tokens in the subcorpus. We’ll calculate these values and store them in a dictionary of dictionaries, a convenient way of building a two-dimensional array in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main data structure\n",
    "features = [word for word,freq in whole_corpus_freq_dist]\n",
    "feature_freqs = {}\n",
    "\n",
    "for author in authors:\n",
    "    # A dictionary for each candidate's features\n",
    "    feature_freqs[author] = {}\n",
    "\n",
    "    # A helper value containing the number of tokens in the author's subcorpus\n",
    "    overall = len(federalist_by_author_tokens[author])\n",
    "\n",
    "    # Calculate each feature's presence in the subcorpus\n",
    "    for feature in features:\n",
    "        presence = federalist_by_author_tokens[author].count(feature)\n",
    "        feature_freqs[author][feature] = presence / overall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating feature averages and standard deviations\n",
    "\n",
    "Given the feature frequencies for all four subcorpora that we have just computed, we can find a “mean of means” and a standard deviation for each feature. We’ll store these values in another “dictionary of dictionaries”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# The data structure into which we will be storing the \"corpus standard\" statistics\n",
    "corpus_features = {}\n",
    "\n",
    "# For each feature...\n",
    "for feature in features:\n",
    "    # Create a sub-dictionary that will contain the feature's mean\n",
    "    # and standard deviation\n",
    "    corpus_features[feature] = {}\n",
    "\n",
    "    # Calculate the mean of the frequencies expressed in the subcorpora\n",
    "    feature_average = 0\n",
    "    for author in authors:\n",
    "        feature_average += feature_freqs[author][feature]\n",
    "    feature_average /= len(authors)\n",
    "    corpus_features[feature][\"Mean\"] = feature_average\n",
    "\n",
    "    # Calculate the standard deviation using the basic formula for a sample\n",
    "    feature_stdev = 0\n",
    "    for author in authors:\n",
    "        diff = feature_freqs[author][feature] - corpus_features[feature][\"Mean\"]\n",
    "        feature_stdev += diff*diff\n",
    "    feature_stdev /= (len(authors) - 1)\n",
    "    feature_stdev = math.sqrt(feature_stdev)\n",
    "    corpus_features[feature][\"StdDev\"] = feature_stdev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating z-scores\n",
    "\n",
    "Next, we transform the observed feature frequencies in the five candidates’ subcorpora into z-scores describing how far away from the “corpus norm” these observations are. Nothing fancy here: we merely apply the definition of the z-score to each feature and store the results into yet another two-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_zscores = {}\n",
    "for author in authors:\n",
    "    feature_zscores[author] = {}\n",
    "    for feature in features:\n",
    "\n",
    "        # Z-score definition = (value - mean) / stddev\n",
    "        # We use intermediate variables to make the code easier to read\n",
    "        feature_val = feature_freqs[author][feature]\n",
    "        feature_mean = corpus_features[feature][\"Mean\"]\n",
    "        feature_stdev = corpus_features[feature][\"StdDev\"]\n",
    "        feature_zscores[author][feature] = ((feature_val-feature_mean) /\n",
    "                                            feature_stdev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating features and z-scores for our test case\n",
    "\n",
    "Next, we need to compare Federalist 64 with the corpus. The following code snippet, which essentially recapitulates everything we have done so far, counts the frequencies of each of our 30 features in Federalist 64 and calculates z-scores accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the test case\n",
    "testcase_tokens = nltk.word_tokenize(federalist_by_author[\"TestCase\"])\n",
    "\n",
    "# Filter out punctuation and lowercase the tokens\n",
    "testcase_tokens = [token.lower() for token in testcase_tokens\n",
    "                   if any(c.isalpha() for c in token)]\n",
    "\n",
    "# Calculate the test case's features\n",
    "overall = len(testcase_tokens)\n",
    "testcase_freqs = {}\n",
    "for feature in features:\n",
    "    presence = testcase_tokens.count(feature)\n",
    "    testcase_freqs[feature] = presence / overall\n",
    "\n",
    "# Calculate the test case's feature z-scores\n",
    "testcase_zscores = {}\n",
    "for feature in features:\n",
    "    feature_val = testcase_freqs[feature]\n",
    "    feature_mean = corpus_features[feature][\"Mean\"]\n",
    "    feature_stdev = corpus_features[feature][\"StdDev\"]\n",
    "    testcase_zscores[feature] = (feature_val - feature_mean) / feature_stdev\n",
    "    print(\"Test case z-score for feature\", feature, \"is\", testcase_zscores[feature])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Delta\n",
    "\n",
    "And finally, we use the formula for Delta defined by Burrows to extract a single score comparing Federalist 64 with each of the five “candidate authors”. **Reminder: the smaller the Delta score, the more similar Federalist 64’s stylometric signature is to the candidate’s.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    delta = 0\n",
    "    for feature in features:\n",
    "        delta += math.fabs((testcase_zscores[feature] -\n",
    "                            feature_zscores[author][feature]))\n",
    "    delta /= len(features)\n",
    "    print( \"Delta score for candidate\", author, \"is\", delta )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results: Delta scores suggest that John Jay indeed wrote Federalist 64.\n",
    "\n",
    "***As expected, Delta identifies John Jay as Federalist 64’s most likely author. It is interesting to note that, according to Delta, Federalist 64 is more similar to the disputed papers than to those known to have been written by Hamilton or by Madison; why that might be, however, is a question for another day.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Reading and Resources\n",
    "Interesting case studies\n",
    "interesting-case-studies\n",
    "\n",
    "Stylometry and/or authorship attribution have been used in many contexts, employing many techniques. Here are but a few interesting case studies:\n",
    "\n",
    "+ Javier de la Rosa and Juan Luis Suárez look for the author or a famous 16th-century Spanish novel from among a considerable list of candidates.19\n",
    "+ Maria Slautina and Mikhail Marusenko use pattern recognition on a set of syntactic, grammatical and lexical features, from simple word counts (with part-of-speech tagging) to various types of phrases, in order to establish stylistic similarity between medieval texts.20\n",
    "+ Ellen Jordan, Hugh Craig and Alexis Antonia look at the case of 19th-century British periodicals, in which articles were usually unsigned, to determine the author of four reviews of works by or about the Brontë sisters.21 This case study applies an early version of another method developed by John Burrows, the Zeta method, which focuses on an author’s favorite words instead of common function words.22\n",
    "Valérie Beaudoin and François Yvon analyse 58 plays in verse by French playwrights Corneille, Racine and Molière, finding that the first two were far more consistent in the way they structured their writing than the latter.23\n",
    "+ Marcelo Luiz Brocardo, Issa Traore, Sherif Saad and Isaac Woungang apply supervised learning and n-gram models to determine the authorship of short messages with large numbers of potential authors, like emails and tweets.24\n",
    "+ Moshe Koppel and Winter Yaron propose the “impostor method”, which attempts to determine whether two texts have been written by the same author by inserting them into a set of texts written by false candidates.25 + Justin Anthony Stover et al. have recently applied the technique to determine the authorship of a newly discovered 2nd-century manuscript.26\n",
    "+ Finally, a team led by David I. Holmes studies the peculiar case of documents written either by a Civil War soldier or by his widow who may intentionally have copied his writing style.27\n",
    "\n",
    "## Additional references on authorship and stylometry\n",
    "\n",
    "The most exhaustive reference in all matters related to authorship attribution, including the history of the field, its mathematical and linguistic underpinnings, and its various methods, was written by Patrick Juola in 2007.28 Chapter 7, in particular, shows how authorship attribution can serve as a marker for various group identities (gender, nationality, dialect, etc.), for change in language over time, and even for personality and mental health.\n",
    "\n",
    "A shorter survey can be found in Moshe Koppel et al., who discuss cases in which there is a single candidate author whose authorship must be confirmed, large numbers of candidates for which only small writing samples are available to train a machine learning algorithm, or no known candidate at all.29\n",
    "\n",
    "The Stamatatos paper cited earlier2 also contains a quality survey of the field.\n",
    "\n",
    "## Varia\n",
    "\n",
    "Programming historians who wish to explore stylometry further may want to download the Stylo package30, which has become a de facto standard. Among other things, Stylo provides an implementation of the Delta method, feature extraction functionality, and convenient graphical user interfaces for both data manipulation and the production of visually appealing results. Note that Stylo is written in R, which means that you will need R installed on your computer to run it, but between the graphical user interface and the tutorials, little or no prior knowledge of R programming should be necessary.\n",
    "\n",
    "Readers fluent in French who are interested in exploring the epistemological implications of the interactions between quantitative and qualitative methods in the analysis of writing style should read Clémence Jacquot.31\n",
    "\n",
    "Somewhat surprisingly, **data obtained through optical character recognition (OCR) have been shown to be adequate for authorship attribution purposes, even when the data suffer from high OCR error rates.**32\n",
    "\n",
    "Readers interested in further discussion of the history of the Federalist Papers and of the various theories advanced regarding their authorship may want to start by reading papers by Irving Brant33 and by Paul Ford and Edward Bourne.34 The topic, however, is almost boundless.\n",
    "\n",
    "Finally, there is a Zotero group dedicated to stylometry, where you can find many more references to methods and studies.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "Thanks to Stéfan Sinclair and Andrew Piper, in whose seminars at McGill University this project began. Also thanks to my thesis advisor, Susan Dalton, whose mentorship in always invaluable.\n",
    "Endnotes\n",
    "\n",
    "    See, for example, Justin Rice, “What Makes Hemingway Hemingway? A statistical analysis of the data behind Hemingway’s style” ↩\n",
    "\n",
    "    Efstathios Stamatatos, “A Survey of Modern Authorship Attribution Method,” Journal of the American Society for Information Science and Technology, vol. 60, no. 3 (December 2008), p. 538–56, citation on p. 540, https://doi.org/10.1002/asi.21001. ↩ ↩2 ↩3\n",
    "\n",
    "    Jan Rybicki, “Vive La Différence: Tracing the (Authorial) Gender Signal by Multivariate Analysis of Word Frequencies,” Digital Scholarship in the Humanities, vol. 31, no. 4 (December 2016), pp. 746–61, https://doi.org/10.1093/llc/fqv023. Sean G. Weidman and James O’Sullivan, “The Limits of Distinctive Words: Re-Evaluating Literature’s Gender Marker Debate,” Digital Scholarship in the Humanities, 2017, https://doi.org/10.1093/llc/fqx017. ↩\n",
    "\n",
    "    Ted Underwood, David Bamman, and Sabrina Lee, “The Transformation of Gender in English-Language Fiction”, Cultural Analytics, Feb. 13, 2018, DOI: 10.7910/DVN/TEGMGI. ↩\n",
    "\n",
    "    Sven Meyer zu Eissen and Benno Stein, “Intrinsic Plagiarism Detection,” in ECIR 2006, edited by Mounia Lalmas, Andy MacFarlane, Stefan Rüger, Anastasios Tombros, Theodora Tsikrika, and Alexei Yavlinsky, Berlin, Heidelberg: Springer, 2006, pp. 565–69, https://doi.org/10.1007/11735106_66. ↩\n",
    "\n",
    "    Cynthia Whissell, “Traditional and Emotional Stylometric Analysis of the Songs of Beatles Paul McCartney and John Lennon,” Computers and the Humanities, vol. 30, no. 3 (1996), pp. 257–65. ↩\n",
    "\n",
    "    Douglass Adair, “The Authorship of the Disputed Federalist Papers”, The William and Mary Quarterly, vol. 1, no. 2 (April 1944), pp. 97-122. ↩\n",
    "\n",
    "    David I. Holmes and Richard S. Forsyth, “The Federalist Revisited: New Directions in Authorship Attribution”, Literary and Linguisting Computing, vol. 10, no. 2 (1995), pp. 111-127. ↩\n",
    "\n",
    "    Frederick Mosteller, “A Statistical Study of the Writing Styles of the Authors of the Federalist Papers”, Proceedings of the American Philosophical Society, vol. 131, no. 2 (1987), pp. 132‑40. ↩\n",
    "\n",
    "    Frederick Mosteller and David Lee Wallace, Inference and Disputed Authorship: The Federalist, Addison-Wesley Series in Behavioral Science : Quantitative Methods (Reading, Mass.: Addison-Wesley PublCo, 1964). ↩\n",
    "\n",
    "    See for example Glenn Fung, “The disputed Federalist papers: SVM feature selection via concave minimization”, TAPIA ‘03: Proceedings of the 2003 conference on Diversity in Computing, pp. 42-46; and Robert A. Bosch and Jason A. Smith, “Separating Hyperplanes and the Authorship of the Disputed Federalist Papers,” The American Mathematical Monthly, vol. 105, no. 7 (1998), pp. 601–8, https://doi.org/10.2307/2589242. ↩\n",
    "\n",
    "    Jeff Collins, David Kaufer, Pantelis Vlachos, Brian Butler and Suguru Ishizaki, “Detecting Collaborations in Text: Comparing the Authors’ Rhetorical Language Choices in The Federalist Papers”, Computers and the Humanities, vol. 38 (2004), pp. 15-36. ↩\n",
    "\n",
    "    Mosteller, “A Statistical Study…”, pp. 132-133. ↩\n",
    "\n",
    "    T. C. Mendenhall, “The Characteristic Curves of Composition”, Science, vol. 9, no. 214 (Mar. 11, 1887), pp. 237-249. ↩\n",
    "\n",
    "    Adam Kilgarriff, “Comparing Corpora”, International Journal of Corpus Linguistics, vol. 6, no. 1 (2001), pp. 97-133. ↩\n",
    "\n",
    "    John Burrows, “‘Delta’: a Measure of Stylistic Difference and a Guide to Likely Authorship”, Literary and Linguistic Computing, vol. 17, no. 3 (2002), pp. 267-287. ↩\n",
    "\n",
    "    Stefan Evert et al., “Understanding and explaining Delta measures for authorship attribution”, Digital Scholarship in the Humanities, vol. 32, no. suppl_2 (2017), pp. ii4-ii16. ↩\n",
    "\n",
    "    José Calvo Tello, “Entendiendo Delta desde las Humanidades,” Caracteres, May 27 2016, http://revistacaracteres.net/revista/vol5n1mayo2016/entendiendo-delta/. ↩\n",
    "\n",
    "    Javier de la Rosa and Juan Luis Suárez, “The Life of Lazarillo de Tormes and of His Machine Learning Adversities,” Lemir, vol. 20 (2016), pp. 373-438. ↩\n",
    "\n",
    "    Maria Slautina and Mikhaïl Marusenko, “L’émergence du style, The emergence of style,” Les Cahiers du numérique, vol. 10, no. 4 (November 2014), pp. 179–215, https://doi.org/10.3166/LCN.10.4.179-215. ↩\n",
    "\n",
    "    Ellen Jordan, Hugh Craig, and Alexis Antonia, “The Brontë Sisters and the ‘Christian Remembrancer’: A Pilot Study in the Use of the ‘Burrows Method’ to Identify the Authorship of Unsigned Articles in the Nineteenth-Century Periodical Press,” Victorian Periodicals Review, vol. 39, no. 1 (2006), pp. 21–45. ↩\n",
    "\n",
    "    John Burrows, “All the Way Through: Testing for Authorship in Different Frequency Strata,” Literary and Linguistic Computing, vol. 22, no. 1 (April 2007), pp. 27–47, https://doi.org/10.1093/llc/fqi067. ↩\n",
    "\n",
    "    Valérie Beaudoin and François Yvon, “Contribution de La Métrique à La Stylométrie,” JADT 2004: 7e Journées internationales d’Analyse statistique des Données Textuelles, vol. 1, Louvain La Neuve, Presses Universitaires de Louvain, 2004, pp. 107–18. ↩\n",
    "\n",
    "    Marcelo Luiz Brocardo, Issa Traore, Sherif Saad and Isaac Woungang, “Authorship Verification for Short Messages Using Stylometry,” 2013 International Conference on Computer, Information and Telecommunication Systems (CITS), 2013, https://doi.org/10.1109/CITS.2013.6705711. ↩\n",
    "\n",
    "    Moshe Koppel and Winter Yaron, “Determining If Two Documents Are Written by the Same Author,” Journal of the Association for Information Science and Technology, vol. 65, no. 1 (October 2013), pp. 178–87, https://doi.org/10.1002/asi.22954. ↩\n",
    "\n",
    "    Justin Anthony Stover et al., “Computational authorship verification method attributes a new work to a major 2nd century African author”, Journal of the Association for Information Science and Technology, vol. 67, no. 1 (2016), pp. 239–242. ↩\n",
    "\n",
    "    David I. Holmes, Lesley J. Gordon, and Christine Wilson, “A widow and her soldier: Stylometry and the American Civil War”, Literary and Linguistic Computing, vol. 16, no 4 (2001), pp. 403–420. ↩\n",
    "\n",
    "    Patrick Juola, “Authorship Attribution,” Foundations and Trends in Information Retrieval, vol. 1, no. 3 (2007), pp. 233–334, https://doi.org/10.1561/1500000005. ↩\n",
    "\n",
    "    Moshe Koppel, Jonathan Schler, and Shlomo Argamon, “Computational Methods in Authorship Attribution,” Journal of the Association for Information Science and Technology. vol. 60, no. 1 (January 2009), pp. 9–26, https://doi.org/10.1002/asi.v60:1. ↩\n",
    "\n",
    "    Maciej Eder, Jan Rybicki, and Mike Kestemont, “Stylometry with R: A Package for Computational Text Analysis,” The R Journal, vol. 8, no. 1 (2016), pp. 107–21. ↩\n",
    "\n",
    "    Clémence Jacquot, “Rêve d’une épiphanie du style: visibilité et saillance en stylistique et en stylométrie,” Revue d’Histoire Littéraire de la France , vol. 116, no. 3 (2016), pp. 619–39. ↩\n",
    "\n",
    "    Patrick Juola, John Noecker Jr, and Michael Ryan, “Authorship Attribution and Optical Character Recognition Errors”, TAL, vol. 53, no. 3 (2012), pp. 101–127. ↩\n",
    "\n",
    "    Irving Brant, “Settling the Authorship of the Federalist”, The American Historical Review, vol. 67, no. 1 (October 1961), pp. 71-75. ↩\n",
    "\n",
    "    Paul Leicester Ford and Edward Gaylord Bourne, “The Authorship of the Federalist”, The American Historical Review, vol. 2, no. 4 (July 1897), pp. 675-687. ↩\n",
    "\n",
    "About the author\n",
    "\n",
    "François Dominic Laramée is a postdoctoral fellow in digital history of medicine at the University of Ottawa, in Canada. He holds master's degrees in computer science and U.S. history and is a former video game designer, TV personality and screenwriter. ORCID id icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
